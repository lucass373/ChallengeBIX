{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os dados\n",
    "data = pd.read_csv('air_system_present_year.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['class'])\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace 'na' with NaN to represent missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.replace('na', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "165    0\n",
      "166    0\n",
      "167    0\n",
      "168    0\n",
      "169    0\n",
      "Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') # Initializing the imputer with the mean strategy\n",
    "imputer.fit(X) # Fitting the imputer to the data\n",
    "X= imputer.transform(X) # Transforming the data with missing values replaced by the mean\n",
    "X = pd.DataFrame(X) # Converting back to DataFrame for easy manipulation\n",
    "\n",
    "missing_values = X.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "165    0\n",
      "166    0\n",
      "167    0\n",
      "168    0\n",
      "169    0\n",
      "Length: 170, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = X.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## veryfing the quantity of 'neg' and 'pos'\n",
    "\n",
    "neg = trucks that had a defect in any system other than the air system.<br>\n",
    "pos = trucks that had defects in the air system.\n",
    "\n",
    "I veryfied that the class is unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "neg    15625\n",
      "pos      375\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#verificando quantidade de caminhões com defeito\n",
    "df_defeito = data['class'].value_counts()\n",
    "print(df_defeito)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing classes with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0\n",
       "0    15625\n",
       "1    15625\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE()\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "pd.DataFrame(y_balanced).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the models and displaying evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating the model: Random Forest\n",
      "accuracy: 1.00\n",
      "precision: 0.99\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3180\n",
      "           1       0.99      1.00      1.00      3070\n",
      "\n",
      "    accuracy                           1.00      6250\n",
      "   macro avg       1.00      1.00      1.00      6250\n",
      "weighted avg       1.00      1.00      1.00      6250\n",
      "\n",
      "============================================================\n",
      "Training and evaluating the model: Decision Tree\n",
      "accuracy: 0.99\n",
      "precision: 0.99\n",
      "Recall: 0.99\n",
      "F1-Score: 0.99\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3180\n",
      "           1       0.99      0.99      0.99      3070\n",
      "\n",
      "    accuracy                           0.99      6250\n",
      "   macro avg       0.99      0.99      0.99      6250\n",
      "weighted avg       0.99      0.99      0.99      6250\n",
      "\n",
      "============================================================\n",
      "Training and evaluating the model: Logistic Regression\n",
      "accuracy: 0.96\n",
      "precision: 0.97\n",
      "Recall: 0.95\n",
      "F1-Score: 0.96\n",
      "\n",
      "classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3180\n",
      "           1       0.97      0.95      0.96      3070\n",
      "\n",
      "    accuracy                           0.96      6250\n",
      "   macro avg       0.96      0.96      0.96      6250\n",
      "weighted avg       0.96      0.96      0.96      6250\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas.oliveira\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training and evaluating the model: {model_name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Avaliar o desempenho do modelo\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Exibir as métricas de avaliação\n",
    "    print(f\"accuracy: {accuracy:.2f}\")\n",
    "    print(f\"precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(\"\\nclassification report:\\n\", report)\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Activities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <strong>--Steps--</strong>\n",
    "#### <strong>1. Analyzing the problem</strong>\n",
    "\n",
    "The main issue in this scenario is the increasing maintenance costs related to the air system of the fleet trucks..<br>\n",
    "\n",
    "#### <strong>2. Exploratory Data Analysis</strong>\n",
    "\n",
    "During the dataset analysis, I located the features and the target variable, where I noticed that the 'class' field could serve as the target for predictions, as it indicates whether a truck has an air system defect.<br>\n",
    "\n",
    "#### <strong>3. Data Preprocessing</strong>\n",
    "\n",
    "As per the case description, missing values are denoted by 'na', so I replaced these with NaN.<br>\n",
    "\n",
    "Next, I handled these NaN values by replacing them with the mean of their respective columns. This approach was chosen to retain potentially valuable data without resorting to deletion, which could lead to information loss.<br>\n",
    "\n",
    "I observed that the 'class' field is in string format and contains only two values, 'pos' and 'neg'. Consequently, I utilized LabelEncoder to transform these categorical values into numerical equivalents (0 and 1).<br>\n",
    "\n",
    "Upon counting the categorical variables, I noted an imbalance. To address this, I applied SMOTE to balance the dataset. This method avoids the removal of data from the majority class, thereby preserving dataset integrity and maintaining model effectiveness.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
